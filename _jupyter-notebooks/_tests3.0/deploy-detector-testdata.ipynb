{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb339c7-4335-4d4d-891e-40a07386e8df",
   "metadata": {},
   "source": [
    "## Deploy Final Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77721ab9-7f1a-471d-99ac-c2e2952e74f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done importing packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kzammit\\Miniconda3\\envs\\ketos_env\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import os \n",
    "import glob\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix as confusion_matrix_sklearn\n",
    "\n",
    "from ketos.data_handling import selection_table as sl\n",
    "import ketos.data_handling.database_interface as dbi\n",
    "from ketos.data_handling.parsing import load_audio_representation\n",
    "from ketos.data_handling.data_feeding import BatchGenerator\n",
    "from ketos.neural_networks.resnet import ResNetInterface\n",
    "from ketos.audio.audio_loader import AudioFrameLoader, AudioLoader, SelectionTableIterator\n",
    "from ketos.audio.spectrogram import MagSpectrogram\n",
    "from ketos.neural_networks.dev_utils.detection import batch_load_audio_file_data, filter_by_threshold, filter_by_label, merge_overlapping_detections\n",
    "from ketos.data_handling.data_feeding import JointBatchGen\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "print('done importing packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bf7a54-2d8c-497c-a83f-3124dc481e79",
   "metadata": {},
   "source": [
    "## Run on all audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8ba699-d549-4e78-9152-68687f166239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/8406 [00:00<?, ?it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 46 samples were padded on the left and 0 samples were padded on the right\n",
      "  4%|███▍                                                                           | 372/8406 [00:42<12:52, 10.40it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 50 samples were padded on the right\n",
      " 47%|█████████████████████████████████████                                         | 3989/8406 [07:05<07:40,  9.60it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 39 samples were padded on the right\n",
      " 49%|██████████████████████████████████████▍                                       | 4139/8406 [07:21<07:27,  9.53it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 25 samples were padded on the right\n",
      " 51%|████████████████████████████████████████▏                                     | 4326/8406 [07:42<07:00,  9.71it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 23 samples were padded on the right\n",
      " 55%|██████████████████████████████████████████▉                                   | 4624/8406 [08:15<06:23,  9.85it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 24 samples were padded on the right\n",
      " 55%|███████████████████████████████████████████▎                                  | 4662/8406 [08:19<06:20,  9.83it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 35 samples were padded on the right\n",
      " 58%|█████████████████████████████████████████████▎                                | 4887/8406 [08:42<05:58,  9.83it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 31 samples were padded on the right\n",
      " 61%|███████████████████████████████████████████████▊                              | 5149/8406 [09:11<05:43,  9.49it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 34 samples were padded on the right\n",
      " 63%|████████████████████████████████████████████████▊                             | 5262/8406 [09:23<05:36,  9.35it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 28 samples were padded on the right\n",
      " 68%|████████████████████████████████████████████████████▉                         | 5711/8406 [10:13<05:01,  8.94it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 13 samples were padded on the right\n",
      " 70%|██████████████████████████████████████████████████████▋                       | 5898/8406 [10:34<04:27,  9.38it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 16 samples were padded on the right\n",
      " 72%|████████████████████████████████████████████████████████                      | 6047/8406 [10:50<04:03,  9.70it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 2 samples were padded on the right\n",
      " 77%|████████████████████████████████████████████████████████████▎                 | 6496/8406 [11:37<03:05, 10.27it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 42 samples were padded on the right\n",
      " 78%|████████████████████████████████████████████████████████████▉                 | 6572/8406 [11:45<03:04,  9.93it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 29 samples were padded on the right\n",
      " 83%|████████████████████████████████████████████████████████████████▊             | 6983/8406 [12:27<02:26,  9.70it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 43 samples were padded on the right\n",
      " 84%|█████████████████████████████████████████████████████████████████▏            | 7020/8406 [12:31<02:25,  9.53it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 11 samples were padded on the right\n",
      " 90%|██████████████████████████████████████████████████████████████████████        | 7544/8406 [13:28<01:29,  9.64it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 38 samples were padded on the right\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 8406/8406 [14:54<00:00,  9.40it/s]\n"
     ]
    }
   ],
   "source": [
    "main_folder = r'E:\\baseline-w-normalization'\n",
    "temp_folder_pp = main_folder + '\\\\' + 'ringedS_tmp_folder'\n",
    "detections_csv = main_folder + '\\\\' + 'detections_raw.csv'\n",
    "spectro_file = r'E:\\baseline-w-normalization\\spec_config_100-1200Hz-0.032-hamm-adjustrange.json'\n",
    "model_name = r'E:\\baseline-w-normalization\\rs-model-4.kt'\n",
    "audio_folder = r'E:\\final-baseline-detector\\audio'\n",
    "\n",
    "# Look at detections above this threshold\n",
    "threshold = 0.5\n",
    "\n",
    "# Step 0.5s each time (overlap of 50% for 1 sec duration)\n",
    "step_size = 0.5\n",
    "\n",
    "# Number of samples in batch\n",
    "batch_size = 16\n",
    "\n",
    "model = ResNetInterface.load(model_file=model_name, new_model_folder=temp_folder_pp)\n",
    "\n",
    "audio_repr = load_audio_representation(path=spectro_file)\n",
    "\n",
    "spec_config = audio_repr['spectrogram']\n",
    "\n",
    "audio_loader = AudioFrameLoader(path=audio_folder, duration=spec_config['duration'],\n",
    "                                    step=step_size, stop=False, representation=spec_config['type'],\n",
    "                                    representation_params=spec_config, pad=False)\n",
    "detections = pd.DataFrame()\n",
    "\n",
    "batch_generator = batch_load_audio_file_data(loader=audio_loader, batch_size=batch_size)\n",
    "\n",
    "for batch_data in batch_generator:\n",
    "    # Run the model on the spectrogram data from the current batch\n",
    "    batch_predictions = model.run_on_batch(batch_data['data'], return_raw_output=True)\n",
    "\n",
    "    # Lets store our data in a dictionary\n",
    "    raw_output = {'filename': batch_data['filename'], 'start': batch_data['start'], 'end': batch_data['end'],\n",
    "                  'score': batch_predictions}\n",
    "\n",
    "    batch_detections = filter_by_threshold(raw_output, threshold=threshold)\n",
    "\n",
    "    detections = pd.concat([detections, batch_detections], ignore_index=True)\n",
    "\n",
    "detections.to_csv(detections_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdc6152-ac1b-426c-a344-7241fc45cfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      filename  start    end  label     score\n",
      "0                  1208795168.700911064318.wav    0.5    1.5      1  0.999533\n",
      "1                  1208795168.700911064318.wav    1.0    2.0      1  0.998006\n",
      "2                  1208795168.700911064318.wav    1.5    2.5      1  0.999894\n",
      "3                  1208795168.700911064318.wav    2.0    3.0      1  0.995934\n",
      "4                  1208795168.700911064318.wav    2.5    3.5      1  0.983766\n",
      "...                                        ...    ...    ...    ...       ...\n",
      "14046  test\\2017-ULU01_0+1_20180323_090602.wav  273.5  274.5      1  0.994432\n",
      "14047  test\\2017-ULU01_0+1_20180323_090602.wav  274.0  275.0      1  0.996855\n",
      "14048  test\\2017-ULU01_0+1_20180323_090602.wav  291.0  292.0      1  0.702005\n",
      "14049  test\\2017-ULU01_0+1_20180323_090602.wav  291.5  292.5      1  0.916594\n",
      "14050  test\\2017-ULU01_0+1_20180323_090602.wav  296.5  297.5      1  0.528207\n",
      "\n",
      "[14051 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the detections for only the positive results \n",
    "detections_filtered = filter_by_label(detections, labels=1).reset_index(drop=True)\n",
    "print(detections_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "895dfdb5-9a7e-4f05-998b-13f07c19fc64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     filename  start    end  label     score\n",
      "0                 1208795168.700911064318.wav    0.5    4.0      1  0.908550\n",
      "1                 1208795168.700911064318.wav    9.0   12.0      1  0.964775\n",
      "2                 1208795168.700911064318.wav   15.5   20.5      1  0.696002\n",
      "3                 1208795168.700911064318.wav   23.5   25.0      1  0.830665\n",
      "4                 1208795168.700911064318.wav   33.0   34.5      1  0.815544\n",
      "...                                       ...    ...    ...    ...       ...\n",
      "4883  test\\2017-ULU01_0+1_20180323_090602.wav  260.0  261.0      1  0.769013\n",
      "4884  test\\2017-ULU01_0+1_20180323_090602.wav  271.0  273.0      1  0.822779\n",
      "4885  test\\2017-ULU01_0+1_20180323_090602.wav  273.5  275.0      1  0.995644\n",
      "4886  test\\2017-ULU01_0+1_20180323_090602.wav  291.0  292.5      1  0.809300\n",
      "4887  test\\2017-ULU01_0+1_20180323_090602.wav  296.5  297.5      1  0.528207\n",
      "\n",
      "[4888 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge overlapping detections \n",
    "#The score of the merged detection is computed as the average of the individual detection scores.\n",
    "\n",
    "detections_grp = merge_overlapping_detections(detections_filtered)\n",
    "print(detections_grp)\n",
    "detections_grp.to_csv(r'E:\\baseline-w-normalization\\pos_detections_all_audio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4e68c6-1853-4a38-9147-05dc4b0bb397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function that compares the upcalls found by the model (detections)\n",
    "#with the upcalls identified by the human expert (annotations).\n",
    "#The function returns the annotation DataFrame with an extra boolean \n",
    "#column indicating if a given annotated upcall was detected by the model.\n",
    "def compare(annotations, detections):\n",
    "\n",
    "    detected_list = []\n",
    "    detections['annotation'] = 'NO'\n",
    "\n",
    "    for idx,row in annotations.iterrows(): #loop over annotations\n",
    "        filename_annot = row['filename']\n",
    "        time_annot = row['start'] + row['end'] /2\n",
    "        detected = False\n",
    "        for _, d in detections.iterrows(): #loop over detections\n",
    "            filename_det = d['filename']\n",
    "            start_det    = d['start']\n",
    "            end_det      = start_det + d['end']\n",
    "            # if the filenames match and the annotated time falls with the start and \n",
    "            # end time of the detection interval, consider the call detected\n",
    "            if filename_annot==filename_det and time_annot >= start_det and time_annot <= end_det:\n",
    "                detections.at[_, 'annotation'] = 'YES'\n",
    "                detected = True\n",
    "                break\n",
    "\n",
    "        detected_list.append(detected)       \n",
    "\n",
    "    annotations['detected'] = detected_list  #add column to the annotations table\n",
    "    detections.to_csv(r'E:\\final-baseline-detector\\pearce-point\\detections-w-annot-flag.csv', index=False)\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "#call the function\n",
    "annots = pd.read_csv(r'E:\\final-baseline-detector\\pearce-point\\PP_2018.2019_AllYear.txt', delimiter='\\t')\n",
    "annotation = compare(annots, detections_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2258294-2db8-408b-b41c-ac67c2ffecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table = pd.read_csv(r'E:\\baseline-w-normalization\\pos_detections_all_audio.csv')\n",
    "audio_folder = r'E:\\final-baseline-detector\\audio'\n",
    "\n",
    "cols = ['filename']\n",
    "results_table.loc[:,cols] = results_table.loc[:,cols].ffill()\n",
    "results_table['Selection'] = results_table.index +1\n",
    "results_table['View'] = 'Spectrogram 1'\n",
    "results_table['Channel'] = 1\n",
    "results_table['Begin Path'] = audio_folder + '\\\\' + results_table.filename\n",
    "results_table['File Offset (s)'] = results_table.start\n",
    "results_table = results_table.rename(columns={\"start\": \"Begin Time (s)\", \"end\": \"End Time (s)\", \"filename\": \"Begin File\"})\n",
    "results_table['Begin File'] = results_table['Begin File']\n",
    "results_table['Low Freq (Hz)'] = 100\n",
    "results_table['High Freq (Hz)'] = 1200\n",
    "\n",
    "results_table.to_csv(r'E:\\baseline-w-normalization\\raven-formatted-detections-model4.txt',\n",
    "                     index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39212c3-b85f-444f-b482-7ef7707cdd66",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ketos_env",
   "language": "python",
   "name": "ketos_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
