{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca10406-9118-409b-b8ff-23800f65d317",
   "metadata": {},
   "source": [
    "# Deploy Normalized Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6363583c-32dd-4563-bbda-3732ebc84dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T02:15:32.907184Z",
     "iopub.status.busy": "2024-03-14T02:15:32.906395Z",
     "iopub.status.idle": "2024-03-14T02:15:32.918969Z",
     "shell.execute_reply": "2024-03-14T02:15:32.918969Z",
     "shell.execute_reply.started": "2024-03-14T02:15:32.907184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done importing packages\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import os \n",
    "import glob\n",
    "import csv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix as confusion_matrix_sklearn\n",
    "\n",
    "from ketos.data_handling import selection_table as sl\n",
    "import ketos.data_handling.database_interface as dbi\n",
    "from ketos.data_handling.parsing import load_audio_representation\n",
    "from ketos.data_handling.data_feeding import BatchGenerator\n",
    "from ketos.neural_networks.resnet import ResNetInterface\n",
    "from ketos.audio.audio_loader import AudioFrameLoader, AudioLoader, SelectionTableIterator\n",
    "from ketos.audio.spectrogram import MagSpectrogram\n",
    "from ketos.neural_networks.dev_utils.detection import batch_load_audio_file_data, filter_by_threshold, filter_by_label, merge_overlapping_detections\n",
    "from ketos.data_handling.data_feeding import JointBatchGen\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "print('done importing packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aefcdc37-4d95-49d1-be31-e1943d762083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T02:15:33.086058Z",
     "iopub.status.busy": "2024-03-14T02:15:33.086058Z",
     "iopub.status.idle": "2024-03-14T02:15:33.099468Z",
     "shell.execute_reply": "2024-03-14T02:15:33.098422Z",
     "shell.execute_reply.started": "2024-03-14T02:15:33.086058Z"
    }
   },
   "outputs": [],
   "source": [
    "main_folder = r'E:\\baseline-with-normalization-reduce-tonal'\n",
    "\n",
    "#model_names = [main_folder + \"\\\\\" + \"rs-model-0.kt\", main_folder + \"\\\\\" + \"rs-model-1.kt\", main_folder + \"\\\\\" + \"rs-model-2.kt\", \n",
    "#            main_folder + \"\\\\\" + \"rs-model-3.kt\", main_folder + \"\\\\\" + \"rs-model-4.kt\", main_folder + \"\\\\\" + \"rs-model-5.kt\",\n",
    "#            main_folder + \"\\\\\" + \"rs-model-6.kt\", main_folder + \"\\\\\" + \"rs-model-7.kt\", main_folder + \"\\\\\" + \"rs-model-8.kt\",\n",
    "#            main_folder + \"\\\\\" + \"rs-model-9.kt\"]\n",
    "\n",
    "model_names = [main_folder + \"\\\\\" + \"rs-model-3.kt\"]\n",
    "\n",
    "spectro_file = r'E:\\baseline-with-normalization-reduce-tonal\\spec_config_100-1200Hz-0.032-hamm-normalized-reduce-tonal.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9fae615-d57d-43e0-a429-05a1744eeef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T02:15:33.296005Z",
     "iopub.status.busy": "2024-03-14T02:15:33.296005Z",
     "iopub.status.idle": "2024-03-14T02:21:04.392125Z",
     "shell.execute_reply": "2024-03-14T02:21:04.390847Z",
     "shell.execute_reply.started": "2024-03-14T02:15:33.296005Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1498 [00:00<?, ?it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 46 samples were padded on the left and 0 samples were padded on the right\n",
      " 12%|█████████▊                                                                     | 187/1498 [00:49<04:43,  4.62it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 46 samples were padded on the right\n",
      " 22%|█████████████████▋                                                             | 336/1498 [01:21<03:54,  4.95it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 43 samples were padded on the right\n",
      " 32%|█████████████████████████▋                                                     | 486/1498 [01:52<03:30,  4.81it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 20 samples were padded on the right\n",
      " 35%|███████████████████████████▋                                                   | 524/1498 [02:00<03:21,  4.82it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 5 samples were padded on the right\n",
      " 40%|███████████████████████████████▌                                               | 598/1498 [02:16<03:07,  4.79it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 12 samples were padded on the right\n",
      " 75%|██████████████████████████████████████████████████████████▍                   | 1122/1498 [04:09<01:16,  4.89it/s]RuntimeWarning: Waveform padded with its own reflection to achieve required length to compute the stft. 0 samples were padded on the left and 33 samples were padded on the right\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1498/1498 [05:30<00:00,  4.54it/s]\n"
     ]
    }
   ],
   "source": [
    "output_dir = r'E:\\baseline-with-normalization-reduce-tonal\\deploy\\ulu2023\\deploy-on-audio'\n",
    "audio_folder = r'D:\\ringed-seal-data\\Ulu_2023_St5_Site65\\test-subset'\n",
    "\n",
    "for idx, model in enumerate(model_names):\n",
    "    \n",
    "    detections_csv = output_dir + '\\\\' + 'detections-model-3-thresh09.csv'\n",
    "    temp_folder = output_dir + '\\\\' + 'ringedS_tmp_folder'\n",
    "    \n",
    "    # Look at detections above this threshold\n",
    "    threshold = 0.9\n",
    "    \n",
    "    # Step 0.5s each time (overlap of 50% for 1 sec duration)\n",
    "    step_size = 0.5\n",
    "    \n",
    "    # Number of samples in batch\n",
    "    batch_size = 16\n",
    "    \n",
    "    model = ResNetInterface.load(model_file=model, new_model_folder=temp_folder)\n",
    "    \n",
    "    audio_repr = load_audio_representation(path=spectro_file)\n",
    "    \n",
    "    spec_config = audio_repr['spectrogram']\n",
    "    \n",
    "    audio_loader = AudioFrameLoader(path=audio_folder, duration=spec_config['duration'],\n",
    "                                        step=step_size, stop=False, representation=spec_config['type'],\n",
    "                                        representation_params=spec_config, pad=False)\n",
    "    detections = pd.DataFrame()\n",
    "    \n",
    "    batch_generator = batch_load_audio_file_data(loader=audio_loader, batch_size=batch_size)\n",
    "    \n",
    "    for batch_data in batch_generator:\n",
    "        # Run the model on the spectrogram data from the current batch\n",
    "        batch_predictions = model.run_on_batch(batch_data['data'], return_raw_output=True)\n",
    "    \n",
    "        # Lets store our data in a dictionary\n",
    "        raw_output = {'filename': batch_data['filename'], 'start': batch_data['start'], 'end': batch_data['end'],\n",
    "                      'score': batch_predictions}\n",
    "    \n",
    "        batch_detections = filter_by_threshold(raw_output, threshold=threshold)\n",
    "    \n",
    "        detections = pd.concat([detections, batch_detections], ignore_index=True)\n",
    "    \n",
    "    detections.to_csv(detections_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ca6fac-c788-45c1-b003-a1d949f0cdc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T02:21:04.393773Z",
     "iopub.status.busy": "2024-03-14T02:21:04.393519Z",
     "iopub.status.idle": "2024-03-14T02:21:04.434932Z",
     "shell.execute_reply": "2024-03-14T02:21:04.434713Z",
     "shell.execute_reply.started": "2024-03-14T02:21:04.393773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  filename  start    end  label     score\n",
      "0    7266.230520000010.wav  147.0  148.0      1  0.998066\n",
      "1    7266.230520000010.wav  147.5  148.5      1  0.964786\n",
      "2    7266.230520000010.wav  186.0  187.0      1  0.968911\n",
      "3    7266.230520000010.wav  254.5  255.5      1  0.999989\n",
      "4    7266.230520000010.wav  255.0  256.0      1  0.999957\n",
      "..                     ...    ...    ...    ...       ...\n",
      "897  7266.230520031510.wav  140.5  141.5      1  0.927529\n",
      "898  7266.230520031510.wav  141.0  142.0      1  0.999995\n",
      "899  7266.230520031510.wav  142.5  143.5      1  0.999846\n",
      "900  7266.230520031510.wav  288.0  289.0      1  1.000000\n",
      "901  7266.230520031510.wav  288.5  289.5      1  1.000000\n",
      "\n",
      "[902 rows x 5 columns]\n",
      "                  filename  start    end  label     score\n",
      "0    7266.230520000010.wav  147.0  148.5      1  0.981426\n",
      "1    7266.230520000010.wav  186.0  187.0      1  0.968911\n",
      "2    7266.230520000010.wav  254.5  256.0      1  0.999973\n",
      "3    7266.230520000010.wav  263.5  265.0      1  0.996683\n",
      "4    7266.230520000510.wav   15.0   16.0      1  0.988584\n",
      "..                     ...    ...    ...    ...       ...\n",
      "357  7266.230520031010.wav  297.0  299.5      1  0.995991\n",
      "358  7266.230520031510.wav   31.5   34.5      1  0.997588\n",
      "359  7266.230520031510.wav  140.5  142.0      1  0.963762\n",
      "360  7266.230520031510.wav  142.5  143.5      1  0.999846\n",
      "361  7266.230520031510.wav  288.0  289.5      1  1.000000\n",
      "\n",
      "[362 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "pos_detection_csv = output_dir + '\\\\' + 'pos_detections_all_audio-model-3-09thresh.csv'\n",
    "raven_txt = output_dir + '\\\\' + 'raven-formatted-detections-model-3-09thresh.txt'\n",
    "\n",
    "# Filter the detections for only the positive results \n",
    "detections_filtered = filter_by_label(detections, labels=1).reset_index(drop=True)\n",
    "print(detections_filtered)\n",
    "\n",
    "# Merge overlapping detections \n",
    "#The score of the merged detection is computed as the average of the individual detection scores.\n",
    "\n",
    "detections_grp = merge_overlapping_detections(detections_filtered)\n",
    "print(detections_grp)\n",
    "detections_grp.to_csv(pos_detection_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e563a5c-cb84-47a0-8dc5-9bd9d2f94f11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T02:21:04.436443Z",
     "iopub.status.busy": "2024-03-14T02:21:04.436207Z",
     "iopub.status.idle": "2024-03-14T02:21:04.475472Z",
     "shell.execute_reply": "2024-03-14T02:21:04.474470Z",
     "shell.execute_reply.started": "2024-03-14T02:21:04.436443Z"
    }
   },
   "outputs": [],
   "source": [
    "results_table = pd.read_csv(pos_detection_csv)\n",
    "\n",
    "cols = ['filename']\n",
    "results_table.loc[:,cols] = results_table.loc[:,cols].ffill()\n",
    "results_table['Selection'] = results_table.index +1\n",
    "results_table['View'] = 'Spectrogram 1'\n",
    "results_table['Channel'] = 1\n",
    "results_table['Begin Path'] = audio_folder + '\\\\' + results_table.filename\n",
    "results_table['File Offset (s)'] = results_table.start\n",
    "results_table = results_table.rename(columns={\"start\": \"Begin Time (s)\", \"end\": \"End Time (s)\", \"filename\": \"Begin File\"})\n",
    "results_table['Begin File'] = results_table['Begin File']\n",
    "results_table['Low Freq (Hz)'] = 100\n",
    "results_table['High Freq (Hz)'] = 1200\n",
    "\n",
    "results_table.to_csv(raven_txt, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd99fcbe-f97a-4749-9d52-635fe513a262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T02:21:04.476923Z",
     "iopub.status.busy": "2024-03-14T02:21:04.476923Z",
     "iopub.status.idle": "2024-03-14T02:21:04.671864Z",
     "shell.execute_reply": "2024-03-14T02:21:04.671864Z",
     "shell.execute_reply.started": "2024-03-14T02:21:04.476923Z"
    }
   },
   "outputs": [],
   "source": [
    "detections_file = pd.read_csv(r'E:\\baseline-with-normalization-reduce-tonal\\deploy\\ulu2023\\deploy-on-audio\\detections-model-3-thresh09.csv')\n",
    "\n",
    "# Filter the detections for only the positive results\n",
    "detections_filtered = filter_by_label(detections_file, labels=1).reset_index(drop=True)\n",
    "\n",
    "detections_grp = merge_overlapping_detections(detections_filtered)\n",
    "\n",
    "one_min_det = pd.DataFrame(columns=['filename', '0-60s', '60-120s', '120-180s', '180-240s', '240+s'])\n",
    "all_files = np.unique(detections_file['filename'])\n",
    "one_min_det['filename'] = all_files\n",
    "one_min_det.set_index('filename', inplace=True)\n",
    "one_min_det = one_min_det.fillna(0)\n",
    "\n",
    "for file in detections_grp['filename'].unique():\n",
    "\n",
    "    temp = detections_grp[detections_grp['filename']==file]\n",
    "    for row in temp.iterrows():\n",
    "        if row[1].end < 60:\n",
    "            one_min_det.at[file, '0-60s'] = one_min_det.loc[file]['0-60s'] + 1\n",
    "        elif row[1].start >= 60 and row[1].end < 120:\n",
    "            one_min_det.at[file, '60-120s'] = one_min_det.loc[file]['60-120s'] + 1\n",
    "        elif row[1].start >= 120 and row[1].end < 180:\n",
    "            one_min_det.at[file, '120-180s'] = one_min_det.loc[file]['120-180s'] + 1\n",
    "        elif row[1].start >= 180 and row[1].end < 240:\n",
    "            one_min_det.at[file, '180-240s'] = one_min_det.loc[file]['180-240s'] + 1\n",
    "        elif row[1].start >= 240:\n",
    "            one_min_det.at[file, '240+s'] = one_min_det.loc[file]['240+s'] + 1\n",
    "\n",
    "one_min_det['total'] = one_min_det.sum(axis=1)\n",
    "one_min_det.to_excel(r'E:\\baseline-with-normalization-reduce-tonal\\deploy\\ulu2023\\deploy-on-audio\\one-min-dets-thresh09.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2651077-a44c-4638-9da5-cac8e264fc03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ketos_env",
   "language": "python",
   "name": "ketos_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
